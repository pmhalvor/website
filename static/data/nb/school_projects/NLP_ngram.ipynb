{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mandatory assignment 1B\n",
    "### by Per Halvorsen, pmhalvor\n",
    "\n",
    "1.   [a](#1a)\n",
    "     [b](#1b)\n",
    "2.   [a](#2a)\n",
    "     [b](#2b)\n",
    "3.   [a](#3a)\n",
    "\n",
    "\n",
    "In this part of the assignment we will look at:\n",
    "- setting up and running experiments\n",
    "- splitting your data into development and test data\n",
    "- *n*-fold cross-validation\n",
    "- models for text classification\n",
    "- Naive Bayes vs Logistic Regression\n",
    "- the scikit-learner toolkit\n",
    "- vectorization of categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1a\n",
    "## First classifier and vectorization\n",
    "\n",
    "We start by importing our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be looking at the Movie Review corpus in NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can import the documents by following the recipe from the scikit “Working with text data” page, using the raw\n",
    "documents which we can get from NLTK by:\n",
    "- `movie_reviews.raw(fileid)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_movie_docs = [(movie_reviews.raw(fileid), category) for\n",
    "category in movie_reviews.categories() for fileid in\n",
    "movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then shuffle the data and split it into 200 documents for final testing (which we will not use for\n",
    "a while) and 1800 documents for development. Make sure to set a random seed, so that the results can be regenerated if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1234)\n",
    "random.shuffle(raw_movie_docs)\n",
    "movie_test = raw_movie_docs[:200]\n",
    "movie_dev = raw_movie_docs[200:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the development data into 1600 documents for training and 200 for development test set,\n",
    "call them `train_data` and `dev_test_data`. \n",
    "\n",
    "The `train_data` should now be a list of 1600 items, where each is a pair of a text represented as a string and a label. You should then split this `train_data` into two lists, each of 1600 elements, the first, `train_texts`, containing the texts (as strings) for each document, and the `train_target`, containing the corresponding 1600 labels. \n",
    "\n",
    "The same is done for `dev_test_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(movie_dev)\n",
    "train_data    = movie_dev[200:]\n",
    "dev_test_data = movie_dev[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text', list, 1600, '///', ' target', list, 1600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unzipped = list(zip(*train_data))\n",
    "train_text   = list(unzipped[0])\n",
    "train_target = list(unzipped[1])\n",
    "'text', type(train_text), len(train_text),'///', ' target', type(train_target), len(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('text', list, 200, '///', ' target', list, 200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unzipped = list(zip(*dev_test_data))\n",
    "dev_test_text   = list(unzipped[0])\n",
    "dev_test_target = list(unzipped[1])\n",
    "'text', type(dev_test_text), len(dev_test_text),'///', ' target', type(dev_test_target), len(dev_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, extract features from the text by using `CountVectorizer`, which was imported above. This first considers the whole set of training data, to determine which features to extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer()\n",
    "v.fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector    = v.transform(train_text)\n",
    "dev_test_vector = v.transform(dev_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This builds a dictionary of features within the documents, feature vectors as the values. These vectors represent the occurrence of that feature across all the reviews in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 36331), (200, 36331))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vector.shape, dev_test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'for': 12538,\n",
       " 'original': 22624,\n",
       " 'sin': 29285,\n",
       " 'the': 32333,\n",
       " 'road': 27268,\n",
       " 'to': 32740,\n",
       " 'screen': 28283,\n",
       " 'has': 14627,\n",
       " 'been': 3204,\n",
       " 'rocky': 27345,\n",
       " 'initially': 16489,\n",
       " 'slated': 29519,\n",
       " 'release': 26455,\n",
       " 'last': 18313,\n",
       " 'november': 22062,\n",
       " 'film': 12066,\n",
       " 'was': 35192,\n",
       " 'bumped': 4618,\n",
       " 'twice': 33506,\n",
       " 'finally': 12097,\n",
       " 'landing': 18226,\n",
       " 'in': 16118,\n",
       " 'dog': 9504,\n",
       " 'days': 8119,\n",
       " 'of': 22317,\n",
       " 'summer': 31361,\n",
       " '2001': 207,\n",
       " 'advance': 1039,\n",
       " 'screenings': 28287,\n",
       " 'were': 35397,\n",
       " 'denied': 8529,\n",
       " 'all': 1373,\n",
       " 'but': 4742,\n",
       " 'few': 11977,\n",
       " 'critics': 7614,\n",
       " 'generally': 13286,\n",
       " 'sign': 29191,\n",
       " 'that': 32330,\n",
       " 'studio': 31102,\n",
       " 'realizes': 25993,\n",
       " 'it': 17066,\n",
       " 'dud': 9936,\n",
       " 'on': 22427,\n",
       " 'its': 17081,\n",
       " 'hands': 14474,\n",
       " 'so': 29874,\n",
       " 'is': 17024,\n",
       " 'really': 25995,\n",
       " 'bad': 2724,\n",
       " 'yes': 36117,\n",
       " 'melodrama': 20225,\n",
       " 'does': 9497,\n",
       " 'offer': 22332,\n",
       " 'some': 29980,\n",
       " 'rewards': 27043,\n",
       " 'location': 18982,\n",
       " 'settings': 28678,\n",
       " 'are': 2030,\n",
       " 'gorgeous': 13786,\n",
       " 'and': 1654,\n",
       " 'there': 32375,\n",
       " 'healthy': 14765,\n",
       " 'sprinkling': 30413,\n",
       " 'with': 35747,\n",
       " 'angelina': 1688,\n",
       " 'jolie': 17409,\n",
       " 'providing': 25262,\n",
       " 'antonio': 1824,\n",
       " 'banderas': 2842,\n",
       " 'more': 21007,\n",
       " 'importantly': 16054,\n",
       " 'movie': 21160,\n",
       " 'entertainingly': 10799,\n",
       " 'veteran': 34687,\n",
       " 'readers': 25963,\n",
       " 'know': 17981,\n",
       " 'as': 2197,\n",
       " 'rule': 27613,\n",
       " 'don': 9565,\n",
       " 'encourage': 10629,\n",
       " 'people': 23584,\n",
       " 'patronize': 23391,\n",
       " 'lousy': 19154,\n",
       " 'films': 12083,\n",
       " 'most': 21077,\n",
       " 'time': 32645,\n",
       " 'plenty': 24218,\n",
       " 'quality': 25546,\n",
       " 'offerings': 22335,\n",
       " 'marketplace': 19767,\n",
       " 'deserving': 8673,\n",
       " 'our': 22699,\n",
       " 'money': 20904,\n",
       " 'besides': 3423,\n",
       " 'let': 18613,\n",
       " 'go': 13639,\n",
       " 'laugh': 18340,\n",
       " 'at': 2362,\n",
       " 'failings': 11610,\n",
       " 'others': 22683,\n",
       " 'mindset': 20572,\n",
       " 'reflects': 26278,\n",
       " 'an': 1607,\n",
       " 'elitism': 10419,\n",
       " 'makes': 19521,\n",
       " 'me': 20105,\n",
       " 'uncomfortable': 33709,\n",
       " 'things': 32423,\n",
       " 'different': 8933,\n",
       " 'this': 32442,\n",
       " 'put': 25503,\n",
       " 'mildly': 20499,\n",
       " 'have': 14679,\n",
       " 'far': 11711,\n",
       " 'between': 3457,\n",
       " 'concerned': 6686,\n",
       " 'fair': 11618,\n",
       " 'find': 12110,\n",
       " 'kicks': 17797,\n",
       " 'where': 35457,\n",
       " 'we': 35273,\n",
       " 'may': 19993,\n",
       " 'will': 35622,\n",
       " 'never': 21711,\n",
       " 'join': 17393,\n",
       " 'such': 31276,\n",
       " 'treasures': 33177,\n",
       " 'valley': 34487,\n",
       " 'dolls': 9533,\n",
       " 'house': 15473,\n",
       " 'showgirls': 29065,\n",
       " 'hall': 14386,\n",
       " 'fame': 11665,\n",
       " 'll': 18939,\n",
       " 'do': 9460,\n",
       " 'until': 34254,\n",
       " 'something': 29991,\n",
       " 'worse': 35902,\n",
       " 'comes': 6435,\n",
       " 'along': 1427,\n",
       " 'adapted': 913,\n",
       " 'by': 4777,\n",
       " 'director': 9051,\n",
       " 'michael': 20420,\n",
       " 'cristofer': 7599,\n",
       " 'from': 12885,\n",
       " 'cornell': 7206,\n",
       " 'woolrich': 35845,\n",
       " 'novel': 22054,\n",
       " 'waltz': 35109,\n",
       " 'into': 16840,\n",
       " 'darkness': 8056,\n",
       " 'which': 35469,\n",
       " 'also': 1442,\n",
       " 'source': 30092,\n",
       " '1969': 166,\n",
       " 'francois': 12738,\n",
       " 'truffaut': 33359,\n",
       " 'mississippi': 20735,\n",
       " 'mermaid': 20327,\n",
       " 'opens': 22489,\n",
       " 'turn': 33455,\n",
       " 'century': 5395,\n",
       " 'prison': 24942,\n",
       " 'character': 5504,\n",
       " 'dawn': 8113,\n",
       " 'execution': 11279,\n",
       " 'tells': 32151,\n",
       " 'her': 14935,\n",
       " 'lurid': 19293,\n",
       " 'tale': 31874,\n",
       " 'priest': 24897,\n",
       " 'who': 35532,\n",
       " 'appears': 1904,\n",
       " 'desperately': 8702,\n",
       " 'horny': 15395,\n",
       " 'freshman': 12825,\n",
       " 'writing': 35978,\n",
       " 'class': 5996,\n",
       " 'tone': 32812,\n",
       " 'quickly': 25595,\n",
       " 'established': 11022,\n",
       " 'when': 35454,\n",
       " 'she': 28859,\n",
       " 'says': 28010,\n",
       " 'like': 18770,\n",
       " 'not': 22007,\n",
       " 'love': 19159,\n",
       " 'story': 30903,\n",
       " 'about': 674,\n",
       " 'wary': 35191,\n",
       " 'local': 18972,\n",
       " 'gold': 13693,\n",
       " 'diggers': 8954,\n",
       " 'cuban': 7751,\n",
       " 'coffee': 6264,\n",
       " 'dealer': 8150,\n",
       " 'luis': 19250,\n",
       " 'vargas': 34535,\n",
       " 'arrangements': 2131,\n",
       " 'secure': 28438,\n",
       " 'mail': 19482,\n",
       " 'order': 22577,\n",
       " 'bride': 4337,\n",
       " 'america': 1539,\n",
       " 'listing': 18891,\n",
       " 'himself': 15092,\n",
       " 'mere': 20312,\n",
       " 'clerk': 6062,\n",
       " 'dissuade': 9343,\n",
       " 'foreign': 12575,\n",
       " 'practical': 24633,\n",
       " 'man': 19579,\n",
       " 'chooses': 5769,\n",
       " 'frumpy': 12910,\n",
       " 'looking': 19075,\n",
       " 'lady': 18163,\n",
       " 'hoping': 15366,\n",
       " 'be': 3088,\n",
       " 'loyal': 19198,\n",
       " 'mate': 19910,\n",
       " 'able': 648,\n",
       " 'provide': 25257,\n",
       " 'him': 15088,\n",
       " 'children': 5704,\n",
       " 'imagine': 15911,\n",
       " 'his': 15140,\n",
       " 'surprise': 31519,\n",
       " 'fianc': 11984,\n",
       " 'julia': 17519,\n",
       " 'russell': 27665,\n",
       " 'turns': 33463,\n",
       " 'out': 22703,\n",
       " 'infinitely': 16393,\n",
       " 'attractive': 2456,\n",
       " 'than': 32320,\n",
       " 'woman': 35796,\n",
       " 'photo': 23888,\n",
       " 'explains': 11390,\n",
       " 'sent': 28582,\n",
       " 'image': 15901,\n",
       " 'because': 3160,\n",
       " 'didn': 8914,\n",
       " 'want': 35132,\n",
       " 'selected': 28501,\n",
       " 'solely': 29951,\n",
       " 'pretty': 24865,\n",
       " 'face': 11561,\n",
       " 'then': 32357,\n",
       " 'confesses': 6758,\n",
       " 'deception': 8223,\n",
       " 'leading': 18423,\n",
       " 'julie': 17523,\n",
       " 'state': 30646,\n",
       " 'great': 13962,\n",
       " 'significance': 29200,\n",
       " 'common': 6505,\n",
       " 'both': 4072,\n",
       " 'trusted': 33375,\n",
       " 'after': 1144,\n",
       " 'their': 32345,\n",
       " 'wedding': 35321,\n",
       " 'retire': 26920,\n",
       " 'glorious': 13612,\n",
       " 'night': 21814,\n",
       " 'carefully': 5095,\n",
       " 'choreographed': 5786,\n",
       " 'lovemaking': 19169,\n",
       " 'bodies': 3884,\n",
       " 'positioned': 24522,\n",
       " 'display': 9284,\n",
       " 'breasts': 4281,\n",
       " 'bottom': 4083,\n",
       " 'erotically': 10949,\n",
       " 'possible': 24542,\n",
       " 'watching': 35221,\n",
       " 'them': 32349,\n",
       " 'naked': 21439,\n",
       " 'fun': 12963,\n",
       " 'although': 1462,\n",
       " 'filmmakers': 12077,\n",
       " 'insistence': 16599,\n",
       " 'using': 34401,\n",
       " 'one': 22433,\n",
       " 'legs': 18523,\n",
       " 'cover': 7387,\n",
       " 'crotch': 7658,\n",
       " 'look': 19069,\n",
       " 'he': 14724,\n",
       " 'trying': 33385,\n",
       " 'climb': 6091,\n",
       " 'stupidest': 31137,\n",
       " 'ever': 11124,\n",
       " 'lived': 18922,\n",
       " 'immediately': 15950,\n",
       " 'instructs': 16656,\n",
       " 'bank': 2863,\n",
       " 'make': 19516,\n",
       " 'personal': 23722,\n",
       " 'business': 4719,\n",
       " 'accounts': 800,\n",
       " 'available': 2570,\n",
       " 'despite': 8708,\n",
       " 'fact': 11580,\n",
       " 'seems': 28473,\n",
       " 'nothing': 22024,\n",
       " 'whom': 35545,\n",
       " 'corresponded': 7242,\n",
       " 'blissful': 3744,\n",
       " 'ignorance': 15841,\n",
       " 'continues': 7025,\n",
       " 'warning': 35170,\n",
       " 'signs': 29208,\n",
       " 'mount': 21127,\n",
       " 'up': 34298,\n",
       " 'must': 21341,\n",
       " 'force': 12547,\n",
       " 'write': 35970,\n",
       " 'sister': 29342,\n",
       " 'emily': 10534,\n",
       " 'frantic': 12751,\n",
       " 'over': 22800,\n",
       " 'lack': 18140,\n",
       " 'communication': 6514,\n",
       " 'shortly': 29023,\n",
       " 'complains': 6579,\n",
       " 'chirping': 5734,\n",
       " 'pet': 23779,\n",
       " 'bird': 3578,\n",
       " 'found': 12680,\n",
       " 'floor': 12384,\n",
       " 'cage': 4840,\n",
       " 'broken': 4427,\n",
       " 'neck': 21588,\n",
       " 'cleans': 6036,\n",
       " 'disappears': 9078,\n",
       " 'begins': 3242,\n",
       " 'suspect': 31556,\n",
       " 'might': 20471,\n",
       " 'wrong': 35981,\n",
       " 'incidentally': 16168,\n",
       " 'if': 15830,\n",
       " 'you': 36165,\n",
       " 're': 25946,\n",
       " 'afraid': 1137,\n",
       " 'giving': 13511,\n",
       " 'too': 32827,\n",
       " 'much': 21201,\n",
       " 'away': 2625,\n",
       " 'rest': 26843,\n",
       " 'assured': 2326,\n",
       " 'happens': 14519,\n",
       " 'first': 12173,\n",
       " '30': 262,\n",
       " 'minutes': 20626,\n",
       " 'leaving': 18456,\n",
       " 'numerous': 22112,\n",
       " 'dopey': 9624,\n",
       " 'plot': 24234,\n",
       " 'twists': 33520,\n",
       " 'deal': 8149,\n",
       " 'operatic': 22496,\n",
       " 'acting': 868,\n",
       " 'footage': 12524,\n",
       " 'tits': 32731,\n",
       " 'ass': 2247,\n",
       " 'way': 35257,\n",
       " 'private': 24950,\n",
       " 'detective': 8741,\n",
       " 'walter': 35105,\n",
       " 'downs': 9714,\n",
       " 'played': 24172,\n",
       " 'thomas': 32447,\n",
       " 'jane': 17159,\n",
       " 'terrific': 32259,\n",
       " 'mickey': 20429,\n",
       " 'mantle': 19682,\n",
       " 'hbo': 14723,\n",
       " '61': 339,\n",
       " 'hired': 15130,\n",
       " 'what': 35438,\n",
       " 'happened': 14516,\n",
       " 'real': 25974,\n",
       " 'eager': 10096,\n",
       " 'track': 32992,\n",
       " 'down': 9694,\n",
       " 'con': 6660,\n",
       " 'artist': 2182,\n",
       " 'having': 14683,\n",
       " 'decided': 8228,\n",
       " 'can': 4951,\n",
       " 'kill': 17830,\n",
       " 'oh': 22362,\n",
       " 'pathos': 23364,\n",
       " 'cast': 5213,\n",
       " 'recognize': 26116,\n",
       " 'trashiness': 33138,\n",
       " 'adjusting': 967,\n",
       " 'performances': 23632,\n",
       " 'accordingly': 790,\n",
       " 'suitably': 31329,\n",
       " 'impassioned': 15996,\n",
       " 'while': 35473,\n",
       " 'alternates': 1456,\n",
       " 'vamping': 34500,\n",
       " 'pouting': 24608,\n",
       " 'those': 32468,\n",
       " 'lips': 18872,\n",
       " 'pout': 24607,\n",
       " 'starts': 30638,\n",
       " 'off': 22320,\n",
       " 'suspicious': 31576,\n",
       " 'cagey': 4843,\n",
       " 'accelerates': 741,\n",
       " 'snidely': 29810,\n",
       " 'whiplash': 35488,\n",
       " 'level': 18637,\n",
       " 'nastiness': 21498,\n",
       " 'startling': 30635,\n",
       " 'moment': 20879,\n",
       " 'prove': 25250,\n",
       " 'power': 24618,\n",
       " 'humiliate': 15602,\n",
       " 'forces': 12551,\n",
       " 'against': 1159,\n",
       " 'wall': 35087,\n",
       " 'verbally': 34639,\n",
       " 'taunts': 32024,\n",
       " 'rubbing': 27569,\n",
       " 'cheeks': 5614,\n",
       " 'finishes': 12133,\n",
       " 'establishing': 11024,\n",
       " 'dominance': 9547,\n",
       " 'full': 12950,\n",
       " 'kiss': 17904,\n",
       " 'anyone': 1840,\n",
       " 'questions': 25585,\n",
       " 'difference': 8931,\n",
       " 'sex': 28713,\n",
       " 'rape': 25843,\n",
       " 'show': 29051,\n",
       " 'chilling': 5710,\n",
       " 'scene': 28072,\n",
       " 'drama': 9756,\n",
       " 'laughable': 18341,\n",
       " 'potboiler': 24573,\n",
       " 'share': 28821,\n",
       " 'descent': 8655,\n",
       " 'talented': 31876,\n",
       " 'boy': 4140,\n",
       " 'pianist': 23919,\n",
       " 'years': 36094,\n",
       " 'later': 18324,\n",
       " 'see': 28454,\n",
       " 'subsequent': 31209,\n",
       " 'resurfacing': 26879,\n",
       " 'mid': 20441,\n",
       " '80': 368,\n",
       " 'damaged': 7968,\n",
       " 'walks': 35085,\n",
       " 'rainstorm': 25753,\n",
       " 'back': 2681,\n",
       " 'world': 35883,\n",
       " 'charts': 5557,\n",
       " 'causes': 5296,\n",
       " 'mental': 20281,\n",
       " 'breakdown': 4268,\n",
       " 'based': 2987,\n",
       " 'life': 18726,\n",
       " 'david': 8102,\n",
       " 'helfgott': 14870,\n",
       " 'australian': 2519,\n",
       " 'rich': 27098,\n",
       " 'exploration': 11412,\n",
       " 'pressures': 24835,\n",
       " 'drilling': 9838,\n",
       " 'upon': 34327,\n",
       " 'child': 5696,\n",
       " 'genius': 13317,\n",
       " 'compounded': 6625,\n",
       " 'looming': 19080,\n",
       " 'shadow': 28750,\n",
       " 'domineering': 9555,\n",
       " 'father': 11777,\n",
       " '1950': 146,\n",
       " 'emerged': 10524,\n",
       " 'prodigy': 25012,\n",
       " 'traces': 32987,\n",
       " 'relationship': 26442,\n",
       " 'whose': 35560,\n",
       " 'encouragement': 10631,\n",
       " 'cost': 7273,\n",
       " 'demanding': 8476,\n",
       " 'no': 21882,\n",
       " 'beyond': 3471,\n",
       " 'black': 3627,\n",
       " 'white': 35517,\n",
       " 'keys': 17772,\n",
       " 'offered': 22333,\n",
       " 'places': 24110,\n",
       " 'usa': 34386,\n",
       " 'refuses': 26304,\n",
       " 'leave': 18454,\n",
       " 'australia': 2518,\n",
       " 'effect': 10260,\n",
       " 'cleverly': 6067,\n",
       " 'told': 32775,\n",
       " 'via': 34700,\n",
       " 'single': 29308,\n",
       " 'reverse': 26987,\n",
       " 'tracked': 32993,\n",
       " 'shot': 29028,\n",
       " 'sobbing': 29886,\n",
       " 'front': 12886,\n",
       " 'doorway': 9619,\n",
       " 'music': 21325,\n",
       " 'teacher': 32051,\n",
       " 'well': 35377,\n",
       " 'lit': 18895,\n",
       " 'external': 11478,\n",
       " 'lights': 18763,\n",
       " 'isn': 17051,\n",
       " 'home': 15267,\n",
       " 'pull': 25387,\n",
       " 'dark': 8049,\n",
       " 'room': 27434,\n",
       " 'window': 35661,\n",
       " 'curtains': 7844,\n",
       " 'open': 22482,\n",
       " 'pool': 24417,\n",
       " 'blackness': 3644,\n",
       " 'grand': 13883,\n",
       " 'piano': 23920,\n",
       " 'fall': 11647,\n",
       " 'cliff': 6080,\n",
       " 'begun': 3248,\n",
       " 'instead': 16634,\n",
       " 'being': 3266,\n",
       " 'linear': 18835,\n",
       " 'mode': 20818,\n",
       " 'shine': 28943,\n",
       " 'jumps': 17540,\n",
       " 'around': 2116,\n",
       " 'ala': 1278,\n",
       " 'pulp': 25395,\n",
       " 'fiction': 11996,\n",
       " 'narrative': 21478,\n",
       " 'device': 8811,\n",
       " 'works': 35881,\n",
       " 'teenager': 32109,\n",
       " 'london': 19039,\n",
       " 'patient': 23368,\n",
       " 'various': 34544,\n",
       " 'snippets': 29824,\n",
       " 'neatly': 21576,\n",
       " 'loops': 19091,\n",
       " 'uplifting': 34319,\n",
       " 'conclusion': 6700,\n",
       " 'adult': 1032,\n",
       " 'return': 26948,\n",
       " 'light': 18750,\n",
       " 'fashion': 11751,\n",
       " 'lead': 18418,\n",
       " 'role': 27370,\n",
       " 'actors': 883,\n",
       " 'teenage': 32107,\n",
       " 'taylor': 32042,\n",
       " 'rush': 27656,\n",
       " 'standing': 30585,\n",
       " 'whilst': 35474,\n",
       " 'known': 17988,\n",
       " 'tv': 33489,\n",
       " 'work': 35863,\n",
       " 'think': 32424,\n",
       " 'major': 19509,\n",
       " 'cinema': 5890,\n",
       " 'clearly': 6046,\n",
       " 'keeps': 17700,\n",
       " 'quoting': 25646,\n",
       " 'daddy': 7928,\n",
       " 'babbling': 2663,\n",
       " 'word': 35852,\n",
       " 'torrent': 32889,\n",
       " 'cuddles': 7764,\n",
       " 'strangers': 30948,\n",
       " 'grabs': 13836,\n",
       " 'women': 35803,\n",
       " 'touching': 32932,\n",
       " 'funny': 12997,\n",
       " 'sympathy': 31756,\n",
       " 'producing': 25018,\n",
       " 'mute': 21357,\n",
       " 'witness': 35763,\n",
       " 'gradual': 13857,\n",
       " 'just': 17570,\n",
       " 'keep': 17697,\n",
       " 'building': 4568,\n",
       " 'wants': 35136,\n",
       " 'play': 24167,\n",
       " 'very': 34677,\n",
       " 'rachmaninov': 25667,\n",
       " '3rd': 291,\n",
       " 'start': 30629,\n",
       " 'simple': 29263,\n",
       " 'mozart': 21184,\n",
       " 'technically': 32083,\n",
       " 'beautiful': 3151,\n",
       " 'lot': 19132,\n",
       " 'thought': 32472,\n",
       " 'gone': 13724,\n",
       " 'production': 25020,\n",
       " 'particularly': 23279,\n",
       " 'use': 34390,\n",
       " 'slow': 29638,\n",
       " 'motion': 21095,\n",
       " 'sound': 30077,\n",
       " 'effects': 10266,\n",
       " 'happily': 14522,\n",
       " 'car': 5068,\n",
       " 'rain': 25739,\n",
       " 'windshield': 35664,\n",
       " 'wipers': 35715,\n",
       " 'fades': 11599,\n",
       " 'voice': 34939,\n",
       " 'clever': 6065,\n",
       " 'subtlety': 31241,\n",
       " 'wiper': 35714,\n",
       " 'morph': 21038,\n",
       " 'rhythmic': 27080,\n",
       " 'thumping': 32549,\n",
       " 'same': 27845,\n",
       " 'beat': 3129,\n",
       " 'dissolves': 9342,\n",
       " 'realise': 25976,\n",
       " 'applause': 1921,\n",
       " 'crowd': 7669,\n",
       " 'us': 34385,\n",
       " 'clapped': 5977,\n",
       " 'young': 36166,\n",
       " 'walking': 35083,\n",
       " 'stage': 30527,\n",
       " 'public': 25348,\n",
       " 'would': 35917,\n",
       " 'expect': 11351,\n",
       " 'subject': 31179,\n",
       " 'matter': 19948,\n",
       " 'critical': 7603,\n",
       " 'miming': 20551,\n",
       " 'playing': 24180,\n",
       " 'faultless': 11791,\n",
       " 'apparently': 1890,\n",
       " 'mime': 20545,\n",
       " 'did': 8908,\n",
       " 'certainly': 5408,\n",
       " 'without': 35760,\n",
       " 'sympathetic': 31747,\n",
       " 'indeed': 16252,\n",
       " 'normal': 21969,\n",
       " 'accelerated': 740,\n",
       " 'chance': 5463,\n",
       " 'meetings': 20189,\n",
       " 'two': 33527,\n",
       " 'special': 30185,\n",
       " 'ultimately': 33602,\n",
       " 'magic': 19439,\n",
       " 'piece': 23952,\n",
       " 'theatre': 32337,\n",
       " 'craft': 7444,\n",
       " 'shows': 29073,\n",
       " 'help': 14892,\n",
       " 'god': 13656,\n",
       " 'damn': 7977,\n",
       " 'dirty': 9062,\n",
       " 'apes': 1860,\n",
       " 'inadvertenty': 16130,\n",
       " 'hilarious': 15070,\n",
       " 'lines': 18842,\n",
       " 'planet': 24127,\n",
       " 'taken': 31862,\n",
       " 'comedic': 6425,\n",
       " 'context': 7012,\n",
       " 'seemed': 28469,\n",
       " 'realize': 25991,\n",
       " 'how': 15495,\n",
       " 'top': 32845,\n",
       " 'charlton': 5543,\n",
       " 'heston': 15008,\n",
       " 'style': 31149,\n",
       " 'now': 22068,\n",
       " 'mystery': 21392,\n",
       " 'science': 28186,\n",
       " 'theater': 32335,\n",
       " '3000': 264,\n",
       " 'wannabe': 35130,\n",
       " 'masterpiece': 19887,\n",
       " 'actually': 892,\n",
       " 'winning': 35690,\n",
       " 'oscar': 22659,\n",
       " 'makeup': 19523,\n",
       " 'less': 18601,\n",
       " 'nominated': 21923,\n",
       " 'couple': 7349,\n",
       " 'spawned': 30172,\n",
       " 'multiple': 21251,\n",
       " 'sequels': 28611,\n",
       " 'beneath': 3351,\n",
       " 'escape': 10980,\n",
       " 'next': 21754,\n",
       " 'generation': 13292,\n",
       " 'police': 24347,\n",
       " 'academy': 738,\n",
       " 'list': 18883,\n",
       " 'goes': 13681,\n",
       " 'american': 1540,\n",
       " 'astronaut': 2350,\n",
       " 'spends': 30240,\n",
       " 'thousand': 32479,\n",
       " 'space': 30115,\n",
       " 'three': 32494,\n",
       " 'companions': 6530,\n",
       " 'ends': 10665,\n",
       " 'dissimilar': 9334,\n",
       " 'earth': 10121,\n",
       " 'thing': 32420,\n",
       " 'humans': 15592,\n",
       " 'talk': 31882,\n",
       " 'or': 22556,\n",
       " 'guys': 14291,\n",
       " 'gorilla': 13790,\n",
       " 'masks': 19851,\n",
       " 'dominant': 9548,\n",
       " 'species': 30194,\n",
       " 'killed': 17832,\n",
       " 'turned': 33459,\n",
       " 'vegetables': 34579,\n",
       " 'apon': 1877,\n",
       " 'imprisoned': 16089,\n",
       " 'surprises': 31521,\n",
       " 'gift': 13440,\n",
       " 'speech': 30217,\n",
       " 'making': 19525,\n",
       " 'primate': 24913,\n",
       " 'scientists': 28191,\n",
       " 'roddy': 27350,\n",
       " 'mcdowall': 20053,\n",
       " 'kim': 17847,\n",
       " 'hunter': 15652,\n",
       " 'believe': 3293,\n",
       " 'missing': 20731,\n",
       " 'link': 18852,\n",
       " 'ape': 1857,\n",
       " 'thinking': 32426,\n",
       " 'present': 24807,\n",
       " 'idea': 15781,\n",
       " 'before': 3221,\n",
       " 'judicial': 17498,\n",
       " 'counsel': 7309,\n",
       " 'head': 14725,\n",
       " 'shakespearean': 28776,\n",
       " 'actor': 882,\n",
       " 'maurice': 19972,\n",
       " 'evans': 11102,\n",
       " 'received': 26070,\n",
       " 'heresy': 14955,\n",
       " 'good': 13731,\n",
       " 'monkeys': 20919,\n",
       " 'created': 7511,\n",
       " 'already': 1440,\n",
       " 'seen': 28474,\n",
       " 'cave': 5308,\n",
       " 'contains': 6982,\n",
       " 'evidence': 11142,\n",
       " 'originally': 22626,\n",
       " 'gained': 13066,\n",
       " 'ability': 646,\n",
       " 'speak': 30175,\n",
       " 'run': 27633,\n",
       " 'president': 24822,\n",
       " 'takes': 31867,\n",
       " 'holding': 15223,\n",
       " 'baby': 2670,\n",
       " 'doll': 9526,\n",
       " 'yelling': 36103,\n",
       " 'couldn': 7304,\n",
       " 'account': 794,\n",
       " 'talking': 31891,\n",
       " 'your': 36172,\n",
       " 'mr': 21189,\n",
       " 'absolute': 696,\n",
       " 'won': 35805,\n",
       " 'reveal': 26965,\n",
       " 'details': 8736,\n",
       " 'except': 11214,\n",
       " 'say': 28004,\n",
       " 'involves': 16952,\n",
       " 'falling': 11651,\n",
       " 'knees': 17953,\n",
       " 'beach': 3090,\n",
       " 'hell': 14877,\n",
       " 'several': 28696,\n",
       " 'times': 32657,\n",
       " 'succession': 31262,\n",
       " 'atrocious': 2397,\n",
       " 'should': 29034,\n",
       " 'only': 22445,\n",
       " 'viewed': 34769,\n",
       " 'members': 20242,\n",
       " 'society': 29901,\n",
       " 'watch': 35211,\n",
       " 'movies': 21173,\n",
       " 'even': 11112,\n",
       " 'amusing': 1602,\n",
       " 'supposed': 31480,\n",
       " 'function': 12965,\n",
       " 'sort': 30061,\n",
       " 'social': 29895,\n",
       " 'irony': 16993,\n",
       " 'condemnation': 6718,\n",
       " 'fundamentals': 12976,\n",
       " 'reject': 26415,\n",
       " 'theories': 32367,\n",
       " 'evolution': 11158,\n",
       " 'tell': 32147,\n",
       " 'darwin': 8076,\n",
       " 'could': 7301,\n",
       " 'hear': 14771,\n",
       " 'rotten': 27498,\n",
       " 'dialogue': 8862,\n",
       " 'exchanges': 11233,\n",
       " 'female': 11904,\n",
       " 'ugly': 33584,\n",
       " 'convert': 7101,\n",
       " 'creationism': 7515,\n",
       " 'spot': 30376,\n",
       " 'luckily': 19225,\n",
       " 'evolved': 11161,\n",
       " 'point': 24306,\n",
       " 'satisfy': 27953,\n",
       " 'every': 11130,\n",
       " 'kind': 17855,\n",
       " 'viewer': 34770,\n",
       " 'sphere': 30250,\n",
       " 'end': 10639,\n",
       " 'pleasing': 24204,\n",
       " 'action': 869,\n",
       " 'lovers': 19171,\n",
       " 'bored': 4038,\n",
       " 'they': 32400,\n",
       " 'interminably': 16760,\n",
       " 'boring': 4043,\n",
       " 'setup': 28685,\n",
       " 'audience': 2475,\n",
       " 'crave': 7487,\n",
       " 'intellectual': 16689,\n",
       " 'fare': 11716,\n",
       " 'disgusted': 9198,\n",
       " 'sudden': 31287,\n",
       " 'collapse': 6325,\n",
       " 'mindless': 20567,\n",
       " 'storytelling': 30912,\n",
       " 'ending': 10654,\n",
       " 'insulting': 16670,\n",
       " 'cop': 7153,\n",
       " 'somewhere': 29998,\n",
       " 'maybe': 19996,\n",
       " 'small': 29674,\n",
       " 'cadre': 4829,\n",
       " 'goers': 13680,\n",
       " 'appreciate': 1938,\n",
       " 'dubious': 9922,\n",
       " 'charms': 5551,\n",
       " 'among': 1569,\n",
       " 'sincerely': 29289,\n",
       " 'hope': 15355,\n",
       " 'better': 3450,\n",
       " 'longer': 19051,\n",
       " 'read': 25960,\n",
       " 'anything': 1841,\n",
       " 'either': 10330,\n",
       " 'crichton': 7572,\n",
       " 'john': 17383,\n",
       " 'grisham': 14057,\n",
       " 'finished': 12132,\n",
       " 'picture': 23943,\n",
       " 'product': 25019,\n",
       " 'hard': 14537,\n",
       " 'understand': 33816,\n",
       " 'why': 35566,\n",
       " 'rights': 27173,\n",
       " 'optioned': 22549,\n",
       " 'mess': 20346,\n",
       " 'line': 18833,\n",
       " 'create': 7510,\n",
       " 'expectations': 11354,\n",
       " 'high': 15047,\n",
       " 'considering': 6900,\n",
       " 'another': 1766,\n",
       " 'barry': 2967,\n",
       " 'levinson': 18647,\n",
       " 'dustin': 10037,\n",
       " 'hoffman': 15206,\n",
       " 'collaboration': 6321,\n",
       " 'excellent': 11211,\n",
       " 'wag': 35039,\n",
       " 'still': 30802,\n",
       " 'theaters': 32336,\n",
       " 'big': 3505,\n",
       " 'name': 21442,\n",
       " 'budget': 4537,\n",
       " 'displayed': 9285,\n",
       " 'ineptitude': 16340,\n",
       " 'year': 36087,\n",
       " 'batman': 3044,\n",
       " 'robin': 27310,\n",
       " 'everyone': 11134,\n",
       " 'knows': 17989,\n",
       " 'little': 18913,\n",
       " 'amalgamation': 1483,\n",
       " 'contact': 6972,\n",
       " 'james': 17150,\n",
       " 'cameron': 4924,\n",
       " 'abyss': 730,\n",
       " 'collapses': 6327,\n",
       " 'cellar': 5355,\n",
       " 'recent': 26075,\n",
       " 'effort': 10276,\n",
       " 'event': 11118,\n",
       " 'horizon': 15378,\n",
       " 'philosophy': 23870,\n",
       " 'used': 34391,\n",
       " 'during': 10027,\n",
       " 'hour': 15469,\n",
       " 'give': 13505,\n",
       " 'confusing': 6805,\n",
       " 'sequences': 28613,\n",
       " 'attempts': 2425,\n",
       " 'characterization': 5509,\n",
       " 'apart': 1852,\n",
       " 'intelligent': 16696,\n",
       " 'evident': 11144,\n",
       " 'early': 10108,\n",
       " 'replaced': 26650,\n",
       " 'hackneyed': 14331,\n",
       " 'drivel': 9851,\n",
       " 'take': 31859,\n",
       " 'plotline': 24238,\n",
       " 'devolves': 8828,\n",
       " 'incoherent': 16190,\n",
       " 'silliness': 29233,\n",
       " 'preparation': 24774,\n",
       " 'inexcusably': 16348,\n",
       " 'awful': 2631,\n",
       " 'honored': 15319,\n",
       " 'deus': 8783,\n",
       " 'ex': 11169,\n",
       " 'machina': 19361,\n",
       " 'worst': 35909,\n",
       " 'left': 18496,\n",
       " 'feeling': 11868,\n",
       " 'cheated': 5596,\n",
       " 'screenwriters': 28296,\n",
       " 'had': 14335,\n",
       " 'chosen': 5794,\n",
       " 'promise': 25109,\n",
       " 'introduced': 16862,\n",
       " 'norman': 21971,\n",
       " 'goodman': 13744,\n",
       " 'psychologist': 25328,\n",
       " 'once': 22431,\n",
       " 'wrote': 35989,\n",
       " '35': 277,\n",
       " '000': 1,\n",
       " 'report': 26667,\n",
       " 'government': 13822,\n",
       " 'crashed': 7476,\n",
       " 'ship': 28948,\n",
       " 'discovered': 9155,\n",
       " 'middle': 20444,\n",
       " 'nowhere': 22070,\n",
       " '1000': 11,\n",
       " 'feet': 11873,\n",
       " 'below': 3329,\n",
       " 'surface': 31496,\n",
       " 'pacific': 22995,\n",
       " 'ocean': 22282,\n",
       " 'called': 4884,\n",
       " 'part': 23263,\n",
       " 'welcoming': 35373,\n",
       " 'committee': 6499,\n",
       " 'team': 32056,\n",
       " 'beth': 3438,\n",
       " 'halperin': 14407,\n",
       " 'sharon': 28831,\n",
       " 'stone': 30866,\n",
       " 'biochemist': 3564,\n",
       " 'student': 31097,\n",
       " 'lover': 19170,\n",
       " 'harry': 14606,\n",
       " 'adams': 907,\n",
       " 'samuel': 27856,\n",
       " ...}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our classification model. We'll start with a multinomial naive bayesian. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(train_vector, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the accuracy of the model directly by using the model's `score()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(dev_test_vector, dev_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1b\n",
    "## Parameters of the vectorizer\n",
    "We have so far considered the standard parameters for the procedures from scikit-learn. These procedures have, however, many parameters. To get optimal results, we should adjust the parameters. We can use `train_data` for training various models and `dev_test_data` for testing and comparing them.\n",
    "\n",
    "We observe that `CountVectorizer` case-folds by default. For a different corpus, it could be interesting to check the effect of this feature, i.e. how often capital letters occur. Here, this has no effect, since the `movie_reviews.raw()` is already all lower case. We could also have explored the effect of exchanging the default tokenizer included in CountVectorizer with other tokenizers.\n",
    "\n",
    "Another interesting feature is `binary`. Setting this to `True` implies only counting whether a word\n",
    "occurs in a document and not how many times it occurs. It could be interesting to see the effect\n",
    "of this feature.\n",
    "\n",
    "(Observe, by the way, that <mark>this is not the same as the Bernoulli model</mark> for text classfication. The\n",
    "<mark>Bernoulli model</mark> takes into consideration <mark>both the probability of being present</mark> for the present words,\n",
    "_as well as_ the probability of <mark>not being present</mark> for the absent words. The binary multinomial model\n",
    "only considers the present words.)\n",
    "\n",
    "The feature `ngram_range=[1,1]` means we use tokens (=unigrams) only, [2,2] means using bigrams\n",
    "only, while [1,2] means both unigrams and bigrams, and so on. Ngrams are groups of $n$ words used next to each other in a sentence. \n",
    "\n",
    "Let's run experiments where we let `binary` vary over `[False, True]` and `ngram_range` vary over `[[1,1],\n",
    "[1,2], [1,3]]` and compare the accuracies with the 6 different settings in a 2x3 table.\n",
    "\n",
    "To do this, we'll need to make use of the `GridSearchCV()` method, which runs a cross-validation for each combination of parameters, and returns the accuracy scores. \n",
    "\n",
    "We'll also need to build a pipeline, which will funnel our data from the `CountVectorizer()` function (with the different parameters), through the transformer, and into the multinomial model. \n",
    "\n",
    "The transformer we will have to use here is different from the one used above, which was built into the `countVectorizer()`method. Instead, we will use `TfidfTransformer()`, which can be used as a step in our pipeline (unlike `v.transform()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB_clf = Pipeline([\n",
    "    ('v', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'v__binary': (True, False),\n",
    "    'v__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(MNB_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(train_text, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v__binary</th>\n",
       "      <th>v__ngram_range</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.811250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.823750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.763750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.826875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v__binary v__ngram_range     score\n",
       "0       True         (1, 1)  0.811250\n",
       "1       True         (1, 2)  0.825000\n",
       "2       True         (1, 3)  0.823750\n",
       "3      False         (1, 1)  0.763750\n",
       "4      False         (1, 2)  0.815000\n",
       "5      False         (1, 3)  0.826875"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.concat([pd.DataFrame(gs_clf.cv_results_['params']), \n",
    "           pd.DataFrame(gs_clf.cv_results_['mean_test_score'], \n",
    "                        columns=['score'])], \n",
    "          axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{type(e): e for e in gs_clf.cv_results_}\n",
    "gs_clf.best_estimator_.named_steps['clf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results shown above tell us that this particular cross-valid found that parameter `binary=True` gave better accuracy than `binary=False`, and that higher `ngram_ranges` gave better scores than lower ranges, for the most part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a\n",
    "# $n$-fold cross validation\n",
    "\n",
    "Our `dev_test_data` contain only 200 items. That is a small number for a test set for a binary classifier. The numbers we report may depend to a large degree on the split between training and test data. To get more reliable numbers, we may use n-fold cross-validation. We can use the whole `movie_dev` of 1800 items for this. To get round numbers, we decide to use 9-fold\n",
    "cross-validation, which will put 200 items in each test set. \n",
    "\n",
    "We can use the best settings from exercise 1 to run a 9-fold cross-validation. and report the accuracy for\n",
    "each run, together with the mean and standard deviation of the 9 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v__binary': True, 'v__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gs_clf.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnb_cv(data, params=best_params, n=9):\n",
    "    '''\n",
    "    Steps:\n",
    "        - shuffle data\n",
    "        - separate text from target\n",
    "        - split into 9 folds\n",
    "        - for each fold:\n",
    "            - ConutVectorize() with optimal paramters\n",
    "            - transform using v.trasnform or tfidf\n",
    "            - fit MNB() model using 8 other folds\n",
    "            - evaluate model using this fold\n",
    "            - report store accuracy score\n",
    "        - report average accuracy scores and std. dev. \n",
    "    '''\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    unzipped = list(zip(*data))\n",
    "    X = list(unzipped[0])\n",
    "    y = list(unzipped[1])\n",
    "    \n",
    "    \n",
    "    binary      = params['v__binary']\n",
    "    ngram_range = params['v__ngram_range']\n",
    "    \n",
    "    clf = Pipeline([\n",
    "        ('v', CountVectorizer(binary=binary, ngram_range=ngram_range)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB())\n",
    "    ])\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    fold_size = len(X)/n\n",
    "    cur = 0\n",
    "    \n",
    "    if fold_size%2==0:\n",
    "        for i in range(1, n+1):\n",
    "            fold = int(fold_size*i)\n",
    "            X_test, y_test = X[cur:fold], y[cur:fold]\n",
    "            X_train = X[:cur] + X[fold:]\n",
    "            y_train = y[:cur] + y[fold:]\n",
    "            \n",
    "            # fit model using pipleine\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # evaluate model\n",
    "            predicted = clf.predict(X_test)\n",
    "            score = np.mean(predicted == y_test)\n",
    "            print(f'Fold {i} accuracy {score}')\n",
    "            scores.append(score)\n",
    "            \n",
    "            # move cursor to start at end of last fold\n",
    "            cur = fold\n",
    "    else:\n",
    "        pass # do nothing if splits not evenly sized\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    sd_scores = np.std(scores)\n",
    "    print(f'Average score {avg_score}')\n",
    "    print(f'Standard dev. {sd_scores}')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy 0.82\n",
      "Fold 2 accuracy 0.85\n",
      "Fold 3 accuracy 0.83\n",
      "Fold 4 accuracy 0.85\n",
      "Fold 5 accuracy 0.855\n",
      "Fold 6 accuracy 0.85\n",
      "Fold 7 accuracy 0.845\n",
      "Fold 8 accuracy 0.885\n",
      "Fold 9 accuracy 0.835\n",
      "Average score 0.8466666666666667\n",
      "Standard dev. 0.01732050807568879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.82, 0.85, 0.83, 0.85, 0.855, 0.85, 0.845, 0.885, 0.835]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_cv(movie_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2b\n",
    "Let's now combine the 9-fold cross-validation with the various settings for CountVectorizer, as we did earlier in [1b](#1b). \n",
    "For each of the 6 settings, run 9-fold cross-validation and calculate the mean accuracy. Report the\n",
    "results in a 2x3 table. Answer: Do you see the same as when you only used one test set?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnb_grid_search(params):\n",
    "    cv_scores = []\n",
    "    \n",
    "    # recursive head to function for getting all parameters\n",
    "    for k in params.keys():\n",
    "        if isinstance(params[k], list):\n",
    "            for v in params[k]:\n",
    "                p = params.copy()\n",
    "                p[k] = v\n",
    "                gs = mnb_grid_search(p)\n",
    "                if len(gs)>0:\n",
    "                    cv_scores += gs\n",
    "            return cv_scores\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    print(params)    \n",
    "\n",
    "    cv_scores+=[[params, mnb_cv(movie_dev, params)]] # should have made movie_dev a default here..\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v__binary': True, 'v__ngram_range': (1, 1)}\n",
      "Fold 1 accuracy 0.845\n",
      "Fold 2 accuracy 0.865\n",
      "Fold 3 accuracy 0.88\n",
      "Fold 4 accuracy 0.865\n",
      "Fold 5 accuracy 0.81\n",
      "Fold 6 accuracy 0.81\n",
      "Fold 7 accuracy 0.81\n",
      "Fold 8 accuracy 0.875\n",
      "Fold 9 accuracy 0.815\n",
      "Average score 0.8416666666666666\n",
      "Standard dev. 0.02867441755680874\n",
      "{'v__binary': True, 'v__ngram_range': (1, 2)}\n",
      "Fold 1 accuracy 0.825\n",
      "Fold 2 accuracy 0.89\n",
      "Fold 3 accuracy 0.905\n",
      "Fold 4 accuracy 0.84\n",
      "Fold 5 accuracy 0.865\n",
      "Fold 6 accuracy 0.88\n",
      "Fold 7 accuracy 0.85\n",
      "Fold 8 accuracy 0.85\n",
      "Fold 9 accuracy 0.815\n",
      "Average score 0.8577777777777779\n",
      "Standard dev. 0.02819683897877674\n",
      "{'v__binary': True, 'v__ngram_range': (1, 3)}\n",
      "Fold 1 accuracy 0.91\n",
      "Fold 2 accuracy 0.845\n",
      "Fold 3 accuracy 0.845\n",
      "Fold 4 accuracy 0.88\n",
      "Fold 5 accuracy 0.85\n",
      "Fold 6 accuracy 0.82\n",
      "Fold 7 accuracy 0.89\n",
      "Fold 8 accuracy 0.83\n",
      "Fold 9 accuracy 0.855\n",
      "Average score 0.8583333333333333\n",
      "Standard dev. 0.027588242262078105\n",
      "{'v__binary': False, 'v__ngram_range': (1, 1)}\n",
      "Fold 1 accuracy 0.76\n",
      "Fold 2 accuracy 0.74\n",
      "Fold 3 accuracy 0.85\n",
      "Fold 4 accuracy 0.83\n",
      "Fold 5 accuracy 0.77\n",
      "Fold 6 accuracy 0.81\n",
      "Fold 7 accuracy 0.8\n",
      "Fold 8 accuracy 0.79\n",
      "Fold 9 accuracy 0.785\n",
      "Average score 0.7927777777777778\n",
      "Standard dev. 0.032413226990699595\n",
      "{'v__binary': False, 'v__ngram_range': (1, 2)}\n",
      "Fold 1 accuracy 0.795\n",
      "Fold 2 accuracy 0.85\n",
      "Fold 3 accuracy 0.795\n",
      "Fold 4 accuracy 0.865\n",
      "Fold 5 accuracy 0.85\n",
      "Fold 6 accuracy 0.82\n",
      "Fold 7 accuracy 0.835\n",
      "Fold 8 accuracy 0.765\n",
      "Fold 9 accuracy 0.795\n",
      "Average score 0.8188888888888889\n",
      "Standard dev. 0.0315152324526285\n",
      "{'v__binary': False, 'v__ngram_range': (1, 3)}\n",
      "Fold 1 accuracy 0.85\n",
      "Fold 2 accuracy 0.825\n",
      "Fold 3 accuracy 0.795\n",
      "Fold 4 accuracy 0.85\n",
      "Fold 5 accuracy 0.8\n",
      "Fold 6 accuracy 0.84\n",
      "Fold 7 accuracy 0.805\n",
      "Fold 8 accuracy 0.805\n",
      "Fold 9 accuracy 0.795\n",
      "Average score 0.8183333333333334\n",
      "Standard dev. 0.02185812841433997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'v__binary': True, 'v__ngram_range': (1, 1)},\n",
       "  [0.845, 0.865, 0.88, 0.865, 0.81, 0.81, 0.81, 0.875, 0.815]],\n",
       " [{'v__binary': True, 'v__ngram_range': (1, 2)},\n",
       "  [0.825, 0.89, 0.905, 0.84, 0.865, 0.88, 0.85, 0.85, 0.815]],\n",
       " [{'v__binary': True, 'v__ngram_range': (1, 3)},\n",
       "  [0.91, 0.845, 0.845, 0.88, 0.85, 0.82, 0.89, 0.83, 0.855]],\n",
       " [{'v__binary': False, 'v__ngram_range': (1, 1)},\n",
       "  [0.76, 0.74, 0.85, 0.83, 0.77, 0.81, 0.8, 0.79, 0.785]],\n",
       " [{'v__binary': False, 'v__ngram_range': (1, 2)},\n",
       "  [0.795, 0.85, 0.795, 0.865, 0.85, 0.82, 0.835, 0.765, 0.795]],\n",
       " [{'v__binary': False, 'v__ngram_range': (1, 3)},\n",
       "  [0.85, 0.825, 0.795, 0.85, 0.8, 0.84, 0.805, 0.805, 0.795]]]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_scores = mnb_grid_search(parameters)\n",
    "gs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8416666666666666,\n",
       " 0.8577777777777779,\n",
       " 0.8583333333333333,\n",
       " 0.7927777777777778,\n",
       " 0.8188888888888889,\n",
       " 0.8183333333333334]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_score_means = [np.mean(s[1]) for s in gs_scores]\n",
    "gs_score_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, False, False, False]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_binary = [s[0]['v__binary'] for s in gs_scores]\n",
    "gs_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (1, 2), (1, 3), (1, 1), (1, 2), (1, 3)]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_ngram  = [s[0]['v__ngram_range'] for s in gs_scores]\n",
    "gs_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>binary</th>\n",
       "      <th>ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841667</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857778</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.858333</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792778</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.818889</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.818333</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  binary ngram_range\n",
       "0  0.841667    True      (1, 1)\n",
       "1  0.857778    True      (1, 2)\n",
       "2  0.858333    True      (1, 3)\n",
       "3  0.792778   False      (1, 1)\n",
       "4  0.818889   False      (1, 2)\n",
       "5  0.818333   False      (1, 3)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_score = pd.DataFrame(zip(gs_score_means, gs_binary, gs_ngram), columns=['score', 'binary', 'ngram_range'])\n",
    "mnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these results looks pretty similar as the table from earlier, with the best parameters: `binary=True` and `ngram_range=(1,3)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a\n",
    "## Logistic Regression\n",
    "We know that Logistic Regression may produce better results than Naive Bayes and want to see what happens if we use this regression method instead of MNB. We start with the same multinomial model for text classification as in exercises (1) and (2) above (i.e. we process the data the same way and use the same vectorizer), but exchange the learner with sciki-learn’s LogisticRegression in our pipeline. \n",
    "\n",
    "Since logistic regression is slow to train, we need to restrict ourselves somewhat with respect to which experiments to run. We consider two settings for the CountVectorizer, the default setting and the setting which gave the best result with naive Bayes (though, this does not have to be the best setting for the logistic regression). \n",
    "\n",
    "For each of the two settings,  we will run a 9-fold cross-validation and calculate the mean accuracy. The results will be compared in a 2x2 table where one axis is Naive Bayes vs. Logistic Regression and the other axis is default settings vs. earlier best settings for CountVectorizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, I will reuse the cv function I created earlier, but change only the last step in our pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_cv(data, params=best_params, n=9):\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    unzipped = list(zip(*data))\n",
    "    X = list(unzipped[0])\n",
    "    y = list(unzipped[1])\n",
    "    \n",
    "    \n",
    "    binary      = params['v__binary']\n",
    "    ngram_range = params['v__ngram_range']\n",
    "    \n",
    "    clf = Pipeline([\n",
    "        ('v', CountVectorizer(binary=binary, ngram_range=ngram_range)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ])\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    fold_size = len(X)/n\n",
    "    cur = 0\n",
    "    \n",
    "    if fold_size%2==0:\n",
    "        for i in range(1, n+1):\n",
    "            fold = int(fold_size*i)\n",
    "            X_test, y_test = X[cur:fold], y[cur:fold]\n",
    "            X_train = X[:cur] + X[fold:]\n",
    "            y_train = y[:cur] + y[fold:]\n",
    "            \n",
    "            # fit model using pipleine\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # evaluate model\n",
    "            predicted = clf.predict(X_test)\n",
    "            score = np.mean(predicted == y_test)\n",
    "            print(f'Fold {i} accuracy {score}')\n",
    "            scores.append(score)\n",
    "            \n",
    "            # move cursor to start at end of last fold\n",
    "            cur = fold\n",
    "    else:\n",
    "        pass # do nothing if splits not evenly sized\n",
    "    \n",
    "    avg_score = np.mean(scores)\n",
    "    sd_scores = np.std(scores)\n",
    "    print(f'Average score {avg_score}')\n",
    "    print(f'Standard dev. {sd_scores}')\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also reuse the grid search function, but change the call to the new cv funciton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_grid_search(params):\n",
    "    cv_scores = []\n",
    "    \n",
    "    # recursive head to function for getting all parameters\n",
    "    for k in params.keys():\n",
    "        if isinstance(params[k], list):\n",
    "            for v in params[k]:\n",
    "                p = params.copy()\n",
    "                p[k] = v\n",
    "                gs = log_grid_search(p)\n",
    "                if len(gs)>0:\n",
    "                    cv_scores += gs\n",
    "            return cv_scores\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    print(params)    \n",
    "\n",
    "    cv_scores+=[[params, log_cv(movie_dev, params)]] # should have made movie_dev a default here..\n",
    "    return cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll also have to create a new dictionary of parameters with the 4 alternatives mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v__binary': True, 'v__ngram_range': (1, 3)}"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_params = {\n",
    "    'v__binary': [True, False],\n",
    "    'v__ngram_range': [(1,1), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to run the grid search for our log. cv. function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v__binary': True, 'v__ngram_range': (1, 1)}\n",
      "Fold 1 accuracy 0.885\n",
      "Fold 2 accuracy 0.885\n",
      "Fold 3 accuracy 0.9\n",
      "Fold 4 accuracy 0.885\n",
      "Fold 5 accuracy 0.835\n",
      "Fold 6 accuracy 0.875\n",
      "Fold 7 accuracy 0.87\n",
      "Fold 8 accuracy 0.885\n",
      "Fold 9 accuracy 0.86\n",
      "Average score 0.8755555555555555\n",
      "Standard dev. 0.017864372434237268\n",
      "{'v__binary': True, 'v__ngram_range': (1, 3)}\n",
      "Fold 1 accuracy 0.86\n",
      "Fold 2 accuracy 0.84\n",
      "Fold 3 accuracy 0.875\n",
      "Fold 4 accuracy 0.845\n",
      "Fold 5 accuracy 0.865\n",
      "Fold 6 accuracy 0.88\n",
      "Fold 7 accuracy 0.825\n",
      "Fold 8 accuracy 0.84\n",
      "Fold 9 accuracy 0.885\n",
      "Average score 0.8572222222222222\n",
      "Standard dev. 0.019594657876164902\n",
      "{'v__binary': False, 'v__ngram_range': (1, 1)}\n",
      "Fold 1 accuracy 0.87\n",
      "Fold 2 accuracy 0.835\n",
      "Fold 3 accuracy 0.815\n",
      "Fold 4 accuracy 0.815\n",
      "Fold 5 accuracy 0.805\n",
      "Fold 6 accuracy 0.815\n",
      "Fold 7 accuracy 0.775\n",
      "Fold 8 accuracy 0.78\n",
      "Fold 9 accuracy 0.86\n",
      "Average score 0.8188888888888889\n",
      "Standard dev. 0.03025610845375577\n",
      "{'v__binary': False, 'v__ngram_range': (1, 3)}\n",
      "Fold 1 accuracy 0.77\n",
      "Fold 2 accuracy 0.755\n",
      "Fold 3 accuracy 0.665\n",
      "Fold 4 accuracy 0.695\n",
      "Fold 5 accuracy 0.74\n",
      "Fold 6 accuracy 0.76\n",
      "Fold 7 accuracy 0.73\n",
      "Fold 8 accuracy 0.79\n",
      "Fold 9 accuracy 0.695\n",
      "Average score 0.7333333333333333\n",
      "Standard dev. 0.03858612300930076\n"
     ]
    }
   ],
   "source": [
    "log_gs_scores = log_grid_search(log_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'v__binary': True, 'v__ngram_range': (1, 1)},\n",
       "  [0.885, 0.885, 0.9, 0.885, 0.835, 0.875, 0.87, 0.885, 0.86]],\n",
       " [{'v__binary': True, 'v__ngram_range': (1, 3)},\n",
       "  [0.86, 0.84, 0.875, 0.845, 0.865, 0.88, 0.825, 0.84, 0.885]],\n",
       " [{'v__binary': False, 'v__ngram_range': (1, 1)},\n",
       "  [0.87, 0.835, 0.815, 0.815, 0.805, 0.815, 0.775, 0.78, 0.86]],\n",
       " [{'v__binary': False, 'v__ngram_range': (1, 3)},\n",
       "  [0.77, 0.755, 0.665, 0.695, 0.74, 0.76, 0.73, 0.79, 0.695]]]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_gs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_gs_score_means = [np.mean(s[1]) for s in log_gs_scores]\n",
    "log_binary = [s[0]['v__binary'] for s in log_gs_scores]\n",
    "log_ngram  = [s[0]['v__ngram_range'] for s in log_gs_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>binary</th>\n",
       "      <th>ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.875556</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857222</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.818889</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  binary ngram_range\n",
       "0  0.875556    True      (1, 1)\n",
       "1  0.857222    True      (1, 3)\n",
       "2  0.818889   False      (1, 1)\n",
       "3  0.733333   False      (1, 3)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_score = pd.DataFrame(zip(log_gs_score_means, log_binary, log_ngram), columns=['score', 'binary', 'ngram_range'])\n",
    "log_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>binary</th>\n",
       "      <th>ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.841667</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857778</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.858333</td>\n",
       "      <td>True</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792778</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.818889</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.818333</td>\n",
       "      <td>False</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  binary ngram_range\n",
       "0  0.841667    True      (1, 1)\n",
       "1  0.857778    True      (1, 2)\n",
       "2  0.858333    True      (1, 3)\n",
       "3  0.792778   False      (1, 1)\n",
       "4  0.818889   False      (1, 2)\n",
       "5  0.818333   False      (1, 3)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naive Bayes</th>\n",
       "      <th>Log. Reg.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.792778</td>\n",
       "      <td>0.818889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.857222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Naive Bayes  Log. Reg.\n",
       "default     0.792778   0.818889\n",
       "best        0.858333   0.857222"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[mnb_score['score'][3], log_score['score'][2]],\n",
    "              [max(mnb_score['score']), log_score['score'][1]]], \n",
    "             columns=['Naive Bayes', 'Log. Reg.'],\n",
    "             index=['default', 'best'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular execution, using the best parameters with Naive Bayes gave a slightly better result than Logistic Regression. However, this was not the best score for Logistic regression. This tells us that we could have found different best parameters had we executed step [1b](#1b) using a Logistic Regression in our pipeline instead of the multinomial naive Bayesian. \n",
    "\n",
    "Another thing we can read from the table is that tuning our parameters specifically for our data set can be quite beneficial. For both models, their respective best parameters gave around a 6 percent point increase in accuracy than the default parameters. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
